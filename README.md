# MENLI

This repository contains the source code for our Paper: [MENLI: Robust Evaluation Metrics from Natural Language Inference](https://arxiv.org/abs/2208.07316).

## Reproducibility
Run [experiments.ipynb](https://github.com/cyr19/MENLI/blob/main/experiments/experiments.ipynb) to reproduce the results for MT and summarization. Before that, download the stored metric scores from [here](https://drive.google.com/file/d/11ucw-Rgyj5G8TJ1KxNowAfnQjCnyKtv2/view?usp=sharing) and unzip it to results/ folder.

## Todo
1. evaluation scripts
2. metric implementation
3. Creation pipeline for Adversarial datasets




